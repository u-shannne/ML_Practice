{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络实现翻译\n",
    "\n",
    "- 参考链接 : https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "\n",
    "- 论文参考链接 : https://arxiv.org/abs/1409.3215\n",
    "\n",
    "In this project we will be teaching a neural network to translate from French to English.\n",
    "\n",
    "最终实现的目标如下\n",
    "\n",
    "```python\n",
    "[KEY: > input, = target, < output]\n",
    "\n",
    "> il est en train de peindre un tableau .\n",
    "= he is painting a picture .\n",
    "< he is painting a picture .\n",
    "\n",
    "> pourquoi ne pas essayer ce vin delicieux ?\n",
    "= why not try that delicious wine ?\n",
    "< why not try that delicious wine ?\n",
    "\n",
    "> elle n est pas poete mais romanciere .\n",
    "= she is not a poet but a novelist .\n",
    "< she not not a poet but a novelist .\n",
    "\n",
    "> vous etes trop maigre .\n",
    "= you re too skinny .\n",
    "< you re all alone .\n",
    "```\n",
    "\n",
    "### 主要思想\n",
    "\n",
    "An encoder network condenses an input sequence into a vector, and a decoder network unfolds that vector into a new sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理&读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    \"\"\"word → index (word2index) and index → word (index2word) dictionaries\n",
    "       A count of each word word2count to use to later replace rare words.\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " we will turn Unicode characters to ASCII, make everything lowercase, \n",
    " and trim most punctuation.\n",
    "\"\"\"\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am a boy ! '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换为ASCII, 大写变小写, 留下重要的标点, 去掉大部分的标点\n",
    "normalizeString('I am a Boy!~$%^&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    \"\"\"逐行读取file, 并将每行分为pair, 并做标准化\n",
    "    \"\"\"\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('./data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了加快训练的速度, 我们把句子长度最大设置为10, 同时我们过滤句子后使得其开头变为如i am, he is等词汇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i am a girl', 'i am a boy']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 会去掉单词个数超过10个的句子\n",
    "# 会去掉不是以特定开头的句子\n",
    "filterPairs([['i am a girl','i am a boy'],\n",
    "             ['how are you','how are you'],\n",
    "            ['i am a girl i am a girl i am a girl','i am a girl i am a girl']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "- Read text file and split into lines, split lines into pairs\n",
    "- Normalize text, filter by length and content\n",
    "- Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    \"\"\"开始读取语言的文件\n",
    "    \"\"\"\n",
    "    # 读取文件, 返回的是句子对\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    # 过滤掉句子对中较长的句子, 和\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n"
     ]
    }
   ],
   "source": [
    "# 开始读取数据\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elles sont mauvaises .', 'they re bad .']\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 2,\n",
       " 'm': 3,\n",
       " '.': 4,\n",
       " 'ok': 5,\n",
       " 'fat': 6,\n",
       " 'fit': 7,\n",
       " 'hit': 8,\n",
       " '!': 9,\n",
       " 'ill': 10,\n",
       " 'sad': 11,\n",
       " 'shy': 12,\n",
       " 'wet': 13,\n",
       " 'he': 14,\n",
       " 's': 15,\n",
       " 'am': 16,\n",
       " 'back': 17,\n",
       " 'bald': 18,\n",
       " 'busy': 19,\n",
       " 'calm': 20,\n",
       " 'cold': 21,\n",
       " 'done': 22,\n",
       " 'fine': 23,\n",
       " 'free': 24,\n",
       " 'full': 25,\n",
       " 'glad': 26,\n",
       " 'home': 27,\n",
       " 'late': 28,\n",
       " 'lazy': 29,\n",
       " 'okay': 30,\n",
       " 'safe': 31,\n",
       " 'sick': 32,\n",
       " 'sure': 33,\n",
       " 'tall': 34,\n",
       " 'thin': 35,\n",
       " 'tidy': 36,\n",
       " 'ugly': 37,\n",
       " 'weak': 38,\n",
       " 'well': 39,\n",
       " 'is': 40,\n",
       " 'old': 41,\n",
       " 'a': 42,\n",
       " 'dj': 43,\n",
       " 'good': 44,\n",
       " 'rich': 45,\n",
       " 'here': 46,\n",
       " 'cop': 47,\n",
       " 'man': 48,\n",
       " 'alone': 49,\n",
       " 'armed': 50,\n",
       " 'awake': 51,\n",
       " 'blind': 52,\n",
       " 'broke': 53,\n",
       " 'crazy': 54,\n",
       " 'cured': 55,\n",
       " 'drunk': 56,\n",
       " 'dying': 57,\n",
       " 'early': 58,\n",
       " 'first': 59,\n",
       " 'fussy': 60,\n",
       " 'going': 61,\n",
       " 'loyal': 62,\n",
       " 'lucky': 63,\n",
       " 'lying': 64,\n",
       " 'quiet': 65,\n",
       " 'ready': 66,\n",
       " 'right': 67,\n",
       " 'sober': 68,\n",
       " 'sorry': 69,\n",
       " 'stuck': 70,\n",
       " 'timid': 71,\n",
       " 'tired': 72,\n",
       " 'tough': 73,\n",
       " 'yours': 74,\n",
       " 'she': 75,\n",
       " 'hot': 76,\n",
       " 'we': 77,\n",
       " 're': 78,\n",
       " 'kind': 79,\n",
       " 'poor': 80,\n",
       " 'swiss': 81,\n",
       " 'smart': 82,\n",
       " 'human': 83,\n",
       " 'french': 84,\n",
       " 'korean': 85,\n",
       " 'hero': 86,\n",
       " 'liar': 87,\n",
       " 'baking': 88,\n",
       " 'better': 89,\n",
       " 'buying': 90,\n",
       " 'chubby': 91,\n",
       " 'eating': 92,\n",
       " 'famous': 93,\n",
       " 'faster': 94,\n",
       " 'flabby': 95,\n",
       " 'greedy': 96,\n",
       " 'hiding': 97,\n",
       " 'honest': 98,\n",
       " 'humble': 99,\n",
       " 'hungry': 100,\n",
       " 'immune': 101,\n",
       " 'in': 102,\n",
       " 'bed': 103,\n",
       " 'joking': 104,\n",
       " 'loaded': 105,\n",
       " 'lonely': 106,\n",
       " 'losing': 107,\n",
       " 'moving': 108,\n",
       " 'normal': 109,\n",
       " 'paying': 110,\n",
       " 'pooped': 111,\n",
       " 'rested': 112,\n",
       " 'ruined': 113,\n",
       " 'shaken': 114,\n",
       " 'single': 115,\n",
       " 'skinny': 116,\n",
       " 'sleepy': 117,\n",
       " 'sneaky': 118,\n",
       " 'strict': 119,\n",
       " 'strong': 120,\n",
       " 'thirty': 121,\n",
       " 'wasted': 122,\n",
       " 'nice': 123,\n",
       " 'are': 124,\n",
       " 'men': 125,\n",
       " 'even': 126,\n",
       " 'lost': 127,\n",
       " 'sunk': 128,\n",
       " 'you': 129,\n",
       " 'bad': 130,\n",
       " 'big': 131,\n",
       " 'fun': 132,\n",
       " 'eight': 133,\n",
       " 'hated': 134,\n",
       " 'nasty': 135,\n",
       " 'young': 136,\n",
       " 'hunk': 137,\n",
       " 'jerk': 138,\n",
       " 'nerd': 139,\n",
       " 'slob': 140,\n",
       " 'asleep': 141,\n",
       " 'coming': 142,\n",
       " 'crying': 143,\n",
       " 'faking': 144,\n",
       " 'my': 145,\n",
       " 'age': 146,\n",
       " 'not': 147,\n",
       " 'cook': 148,\n",
       " 'monk': 149,\n",
       " 'taller': 150,\n",
       " 'too': 151,\n",
       " 'finnish': 152,\n",
       " 'italian': 153,\n",
       " 'baker': 154,\n",
       " 'all': 155,\n",
       " 'set': 156,\n",
       " 'ashamed': 157,\n",
       " 'at': 158,\n",
       " 'baffled': 159,\n",
       " 'blessed': 160,\n",
       " 'careful': 161,\n",
       " 'certain': 162,\n",
       " 'chicken': 163,\n",
       " 'correct': 164,\n",
       " 'curious': 165,\n",
       " 'dancing': 166,\n",
       " 'dieting': 167,\n",
       " 'driving': 168,\n",
       " 'engaged': 169,\n",
       " 'excited': 170,\n",
       " 'fasting': 171,\n",
       " 'finicky': 172,\n",
       " 'frantic': 173,\n",
       " 'furious': 174,\n",
       " 'healthy': 175,\n",
       " 'humming': 176,\n",
       " 'luck': 177,\n",
       " 'jealous': 178,\n",
       " 'jittery': 179,\n",
       " 'kidding': 180,\n",
       " 'leaving': 181,\n",
       " 'married': 182,\n",
       " 'no': 183,\n",
       " 'fool': 184,\n",
       " 'mad': 185,\n",
       " 'on': 186,\n",
       " 'duty': 187,\n",
       " 'patient': 188,\n",
       " 'popular': 189,\n",
       " 'psyched': 190,\n",
       " 'psychic': 191,\n",
       " 'puzzled': 192,\n",
       " 'reading': 193,\n",
       " 'relaxed': 194,\n",
       " 'retired': 195,\n",
       " 'selfish': 196,\n",
       " 'serious': 197,\n",
       " 'shocked': 198,\n",
       " 'sincere': 199,\n",
       " 'sloshed': 200,\n",
       " 'so': 201,\n",
       " 'starved': 202,\n",
       " 'staying': 203,\n",
       " 'stuffed': 204,\n",
       " 'stunned': 205,\n",
       " 'talking': 206,\n",
       " 'teasing': 207,\n",
       " 'thirsty': 208,\n",
       " 'through': 209,\n",
       " 'touched': 210,\n",
       " 'unhappy': 211,\n",
       " 'unlucky': 212,\n",
       " 'wealthy': 213,\n",
       " 'winning': 214,\n",
       " 'working': 215,\n",
       " 'worried': 216,\n",
       " 'curt': 217,\n",
       " 'dead': 218,\n",
       " 'dog': 219,\n",
       " 'fox': 220,\n",
       " 'they': 221,\n",
       " 'angry': 222,\n",
       " 'bored': 223,\n",
       " 'happy': 224,\n",
       " 'saved': 225,\n",
       " 'twins': 226,\n",
       " 'cool': 227,\n",
       " 'fair': 228,\n",
       " 'nuts': 229,\n",
       " 'rude': 230,\n",
       " 'poet': 231,\n",
       " 'cranky': 232,\n",
       " 'heroic': 233,\n",
       " 'english': 234,\n",
       " 'bigot': 235,\n",
       " 'pain': 236,\n",
       " 'out': 237,\n",
       " 'now': 238,\n",
       " 'cute': 239,\n",
       " 'coward': 240,\n",
       " 'doctor': 241,\n",
       " 'farmer': 242,\n",
       " 'purist': 243,\n",
       " 'addicted': 244,\n",
       " 'ears': 245,\n",
       " 'an': 246,\n",
       " 'adult': 247,\n",
       " 'agent': 248,\n",
       " 'bleeding': 249,\n",
       " 'confused': 250,\n",
       " 'creative': 251,\n",
       " 'cultured': 252,\n",
       " 'divorced': 253,\n",
       " 'drowning': 254,\n",
       " 'eighteen': 255,\n",
       " 'faithful': 256,\n",
       " 'famished': 257,\n",
       " 'fearless': 258,\n",
       " 'fighting': 259,\n",
       " 'finished': 260,\n",
       " 'freezing': 261,\n",
       " 'grounded': 262,\n",
       " 'gullible': 263,\n",
       " 'homesick': 264,\n",
       " 'hungover': 265,\n",
       " 'paris': 266,\n",
       " 'innocent': 267,\n",
       " 'involved': 268,\n",
       " 'managing': 269,\n",
       " 'new': 270,\n",
       " 'rebel': 271,\n",
       " 'saint': 272,\n",
       " 'deaf': 273,\n",
       " 'dumb': 274,\n",
       " 'evil': 275,\n",
       " 'hurt': 276,\n",
       " 'mean': 277,\n",
       " 'off': 278,\n",
       " 'offended': 279,\n",
       " 'outraged': 280,\n",
       " 'powerful': 281,\n",
       " 'prepared': 282,\n",
       " 'punctual': 283,\n",
       " 'rational': 284,\n",
       " 'reformed': 285,\n",
       " 'reliable': 286,\n",
       " 'restless': 287,\n",
       " 'ruthless': 288,\n",
       " 'shooting': 289,\n",
       " 'sleeping': 290,\n",
       " 'speaking': 291,\n",
       " 'starving': 292,\n",
       " 'stubborn': 293,\n",
       " 'the': 294,\n",
       " 'boss': 295,\n",
       " 'thinking': 296,\n",
       " 'thorough': 297,\n",
       " 'thrilled': 298,\n",
       " 'ticklish': 299,\n",
       " 'truthful': 300,\n",
       " 'unbiased': 301,\n",
       " 'upstairs': 302,\n",
       " 'very': 303,\n",
       " 'worn': 304,\n",
       " 'sharp': 305,\n",
       " 'wrong': 306,\n",
       " 'boys': 307,\n",
       " 'cops': 308,\n",
       " 'gone': 309,\n",
       " 'mine': 310,\n",
       " 'arabs': 311,\n",
       " 'team': 312,\n",
       " 'adults': 313,\n",
       " 'war': 314,\n",
       " 'biased': 315,\n",
       " 'closed': 316,\n",
       " 'dating': 317,\n",
       " 'doomed': 318,\n",
       " 'inside': 319,\n",
       " 'trying': 320,\n",
       " 'bossy': 321,\n",
       " 'cruel': 322,\n",
       " 'fired': 323,\n",
       " 'funny': 324,\n",
       " 'gross': 325,\n",
       " 'moody': 326,\n",
       " 'naive': 327,\n",
       " 'silly': 328,\n",
       " 'upset': 329,\n",
       " 'weird': 330,\n",
       " 'british': 331,\n",
       " 'thief': 332,\n",
       " 'foolish': 333,\n",
       " 'type': 334,\n",
       " 'running': 335,\n",
       " 'skating': 336,\n",
       " 'grouch': 337,\n",
       " 'jesuit': 338,\n",
       " 'senior': 339,\n",
       " 'tycoon': 340,\n",
       " 'adorable': 341,\n",
       " 'after': 342,\n",
       " 'me': 343,\n",
       " 'annoying': 344,\n",
       " 'demented': 345,\n",
       " 'tokyo': 346,\n",
       " 'insecure': 347,\n",
       " 'studying': 348,\n",
       " 'slow': 349,\n",
       " 'your': 350,\n",
       " 'son': 351,\n",
       " 'american': 352,\n",
       " 'japanese': 353,\n",
       " 'muslim': 354,\n",
       " 'runner': 355,\n",
       " 'diabetic': 356,\n",
       " 'student': 357,\n",
       " 'teacher': 358,\n",
       " 'adaptable': 359,\n",
       " 'afraid': 360,\n",
       " 'ambitious': 361,\n",
       " 'artist': 362,\n",
       " 'orphan': 363,\n",
       " 'attentive': 364,\n",
       " 'available': 365,\n",
       " 'beautiful': 366,\n",
       " 'concerned': 367,\n",
       " 'confident': 368,\n",
       " 'contented': 369,\n",
       " 'convinced': 370,\n",
       " 'depressed': 371,\n",
       " 'desperate': 372,\n",
       " 'different': 373,\n",
       " 'disgusted': 374,\n",
       " 'easygoing': 375,\n",
       " 'exhausted': 376,\n",
       " 'forgetful': 377,\n",
       " 'tom': 378,\n",
       " 'hung': 379,\n",
       " 'over': 380,\n",
       " 'impatient': 381,\n",
       " 'important': 382,\n",
       " 'impressed': 383,\n",
       " 'impulsive': 384,\n",
       " 'boston': 385,\n",
       " 'danger': 386,\n",
       " 'intrigued': 387,\n",
       " 'just': 388,\n",
       " 'listening': 389,\n",
       " 'motivated': 390,\n",
       " 'expert': 391,\n",
       " 'fan': 392,\n",
       " 'obese': 393,\n",
       " 'short': 394,\n",
       " 'observant': 395,\n",
       " 'diet': 396,\n",
       " 'way': 397,\n",
       " 'plastered': 398,\n",
       " 'powerless': 399,\n",
       " 'realistic': 400,\n",
       " 'resentful': 401,\n",
       " 'resilient': 402,\n",
       " 'satisfied': 403,\n",
       " 'saying': 404,\n",
       " 'sensitive': 405,\n",
       " 'surprised': 406,\n",
       " 'surviving': 407,\n",
       " 'terrified': 408,\n",
       " 'uninsured': 409,\n",
       " 'unmarried': 410,\n",
       " 'voting': 411,\n",
       " 'falling': 412,\n",
       " 'twin': 413,\n",
       " 'active': 414,\n",
       " 'gentle': 415,\n",
       " 'cutie': 416,\n",
       " 'model': 417,\n",
       " 'awesome': 418,\n",
       " 'asian': 419,\n",
       " 'alive': 420,\n",
       " 'brave': 421,\n",
       " 'clean': 422,\n",
       " 'small': 423,\n",
       " 'spies': 424,\n",
       " 'there': 425,\n",
       " 'group': 426,\n",
       " 'anxious': 427,\n",
       " 'cousins': 428,\n",
       " 'friends': 429,\n",
       " 'love': 430,\n",
       " 'sync': 431,\n",
       " 'town': 432,\n",
       " 'sinking': 433,\n",
       " 'smashed': 434,\n",
       " 'special': 435,\n",
       " 'stalled': 436,\n",
       " 'trapped': 437,\n",
       " 'useless': 438,\n",
       " 'waiting': 439,\n",
       " 'winners': 440,\n",
       " 'doll': 441,\n",
       " 'snob': 442,\n",
       " 'boring': 443,\n",
       " 'bright': 444,\n",
       " 'clever': 445,\n",
       " 'crafty': 446,\n",
       " 'creepy': 447,\n",
       " 'grumpy': 448,\n",
       " 'insane': 449,\n",
       " 'pretty': 450,\n",
       " 'stupid': 451,\n",
       " 'unfair': 452,\n",
       " 'canadian': 453,\n",
       " 'genius': 454,\n",
       " 'writer': 455,\n",
       " 'actor': 456,\n",
       " 'bankrupt': 457,\n",
       " 'uncle': 458,\n",
       " 'outgoing': 459,\n",
       " 'bit': 460,\n",
       " 'gambler': 461,\n",
       " 'slacker': 462,\n",
       " 'author': 463,\n",
       " 'ex': 464,\n",
       " 'con': 465,\n",
       " 'outlaw': 466,\n",
       " 'henpecked': 467,\n",
       " 'prison': 468,\n",
       " 'friend': 469,\n",
       " 'open': 470,\n",
       " 'hungarian': 471,\n",
       " 'boy': 472,\n",
       " 'tourist': 473,\n",
       " 'him': 474,\n",
       " 'london': 475,\n",
       " 'spot': 476,\n",
       " 'today': 477,\n",
       " 'guy': 478,\n",
       " 'musician': 479,\n",
       " 'real': 480,\n",
       " 'salesman': 481,\n",
       " 'against': 482,\n",
       " 'it': 483,\n",
       " 'thumbs': 484,\n",
       " 'astonished': 485,\n",
       " 'behind': 486,\n",
       " 'being': 487,\n",
       " 'used': 488,\n",
       " 'contagious': 489,\n",
       " 'dehydrated': 490,\n",
       " 'dependable': 491,\n",
       " 'devastated': 492,\n",
       " 'doing': 493,\n",
       " 'downstairs': 494,\n",
       " 'exercising': 495,\n",
       " 'farsighted': 496,\n",
       " 'fascinated': 497,\n",
       " 'firing': 498,\n",
       " 'from': 499,\n",
       " 'kyoto': 500,\n",
       " 'having': 501,\n",
       " 'illiterate': 502,\n",
       " 'car': 503,\n",
       " 'interested': 504,\n",
       " 'making': 505,\n",
       " 'tea': 506,\n",
       " 'meditating': 507,\n",
       " 'methodical': 508,\n",
       " 'quitter': 509,\n",
       " 'amused': 510,\n",
       " 'bitter': 511,\n",
       " 'guilty': 512,\n",
       " 'racist': 513,\n",
       " 'scared': 514,\n",
       " 'enough': 515,\n",
       " 'holiday': 516,\n",
       " 'one': 517,\n",
       " 'of': 518,\n",
       " 'optimistic': 519,\n",
       " 'gas': 520,\n",
       " 'prejudiced': 521,\n",
       " 'really': 522,\n",
       " 'reasonable': 523,\n",
       " 'remodeling': 524,\n",
       " 'still': 525,\n",
       " 'successful': 526,\n",
       " 'killer': 527,\n",
       " 'oldest': 528,\n",
       " 'undressing': 529,\n",
       " 'unemployed': 530,\n",
       " 'untalented': 531,\n",
       " 'to': 532,\n",
       " 'vegetarian': 533,\n",
       " 'wide': 534,\n",
       " 'nurse': 535,\n",
       " 'awkward': 536,\n",
       " 'isn': 537,\n",
       " 't': 538,\n",
       " 'beauty': 539,\n",
       " 'hottie': 540,\n",
       " 'looker': 541,\n",
       " 'angel': 542,\n",
       " 'pregnant': 543,\n",
       " 'loud': 544,\n",
       " 'babies': 545,\n",
       " 'idiots': 546,\n",
       " 'couple': 547,\n",
       " 'family': 548,\n",
       " 'brothers': 549,\n",
       " 'escaping': 550,\n",
       " 'grateful': 551,\n",
       " 'helpless': 552,\n",
       " 'obedient': 553,\n",
       " 'partners': 554,\n",
       " 'quitting': 555,\n",
       " 'retiring': 556,\n",
       " 'standing': 557,\n",
       " 'students': 558,\n",
       " 'best': 559,\n",
       " 'last': 560,\n",
       " 'same': 561,\n",
       " 'up': 562,\n",
       " 'morons': 563,\n",
       " 'aren': 564,\n",
       " 'prude': 565,\n",
       " 'amazing': 566,\n",
       " 'amusing': 567,\n",
       " 'callous': 568,\n",
       " 'elusive': 569,\n",
       " 'invited': 570,\n",
       " 'help': 571,\n",
       " 'precise': 572,\n",
       " 'pro': 573,\n",
       " 'welcome': 574,\n",
       " 'dreamer': 575,\n",
       " 'painter': 576,\n",
       " 'paid': 577,\n",
       " 'comedian': 578,\n",
       " 'frat': 579,\n",
       " 'freshman': 580,\n",
       " 'gardener': 581,\n",
       " 'newcomer': 582,\n",
       " 'slowpoke': 583,\n",
       " 'southpaw': 584,\n",
       " 'helping': 585,\n",
       " 'husband': 586,\n",
       " 'partner': 587,\n",
       " 'yet': 588,\n",
       " 'his': 589,\n",
       " 'photogenic': 590,\n",
       " 'bachelor': 591,\n",
       " 'egypt': 592,\n",
       " 'trouble': 593,\n",
       " 'azerbaijani': 594,\n",
       " 'tv': 595,\n",
       " 'addict': 596,\n",
       " 'tipsy': 597,\n",
       " 'foreigner': 598,\n",
       " 'housewife': 599,\n",
       " 'masochist': 600,\n",
       " 'night': 601,\n",
       " 'owl': 602,\n",
       " 'able': 603,\n",
       " 'run': 604,\n",
       " 'ski': 605,\n",
       " 'about': 606,\n",
       " 'adventurous': 607,\n",
       " 'engineer': 608,\n",
       " 'work': 609,\n",
       " 'begging': 610,\n",
       " 'catching': 611,\n",
       " 'celebrating': 612,\n",
       " 'cleaned': 613,\n",
       " 'color': 614,\n",
       " 'comfortable': 615,\n",
       " 'cooperating': 616,\n",
       " 'cracking': 617,\n",
       " 'embarrassed': 618,\n",
       " 'feeling': 619,\n",
       " 'low': 620,\n",
       " 'brazil': 621,\n",
       " 'france': 622,\n",
       " 'turkey': 623,\n",
       " 'zambia': 624,\n",
       " 'getting': 625,\n",
       " 'hardworking': 626,\n",
       " 'heartbroken': 627,\n",
       " 'win': 628,\n",
       " 'hurry': 629,\n",
       " 'interfering': 630,\n",
       " 'introverted': 631,\n",
       " 'left': 632,\n",
       " 'handed': 633,\n",
       " 'nearsighted': 634,\n",
       " 'child': 635,\n",
       " 'crook': 636,\n",
       " 'robot': 637,\n",
       " 'alarmed': 638,\n",
       " 'arguing': 639,\n",
       " 'nervous': 640,\n",
       " 'perfect': 641,\n",
       " 'unarmed': 642,\n",
       " 'vacation': 643,\n",
       " 'only': 644,\n",
       " 'ammo': 645,\n",
       " 'persevering': 646,\n",
       " 'quite': 647,\n",
       " 'rather': 648,\n",
       " 'go': 649,\n",
       " 'replaceable': 650,\n",
       " 'resourceful': 651,\n",
       " 'spontaneous': 652,\n",
       " 'such': 653,\n",
       " 'sympathetic': 654,\n",
       " 'captain': 655,\n",
       " 'surgeon': 656,\n",
       " 'truly': 657,\n",
       " 'trustworthy': 658,\n",
       " 'unambitious': 659,\n",
       " 'unconvinced': 660,\n",
       " 'modest': 661,\n",
       " 'watching': 662,\n",
       " 'lawyer': 663,\n",
       " 'sister': 664,\n",
       " 'singer': 665,\n",
       " 'typist': 666,\n",
       " 'graceful': 667,\n",
       " 'assertive': 668,\n",
       " 'roll': 669,\n",
       " 'actors': 670,\n",
       " 'melons': 671,\n",
       " 'animals': 672,\n",
       " 'doctors': 673,\n",
       " 'outside': 674,\n",
       " 'similar': 675,\n",
       " 'smiling': 676,\n",
       " 'with': 677,\n",
       " 'sons': 678,\n",
       " 'teachers': 679,\n",
       " 'canadians': 680,\n",
       " 'both': 681,\n",
       " 'comedians': 682,\n",
       " 'committed': 683,\n",
       " 'dedicated': 684,\n",
       " 'fixing': 685,\n",
       " 'flattered': 686,\n",
       " 'gardeners': 687,\n",
       " 'gentlemen': 688,\n",
       " 'giving': 689,\n",
       " 'charge': 690,\n",
       " 'newcomers': 691,\n",
       " 'newlyweds': 692,\n",
       " 'fools': 693,\n",
       " 'past': 694,\n",
       " 'that': 695,\n",
       " 'prisoners': 696,\n",
       " 'resigning': 697,\n",
       " 'separated': 698,\n",
       " 'survivors': 699,\n",
       " 'close': 700,\n",
       " 'unrelated': 701,\n",
       " 'naughty': 702,\n",
       " 'tallest': 703,\n",
       " 'idiot': 704,\n",
       " 'arrogant': 705,\n",
       " 'blushing': 706,\n",
       " 'careless': 707,\n",
       " 'charming': 708,\n",
       " 'cheating': 709,\n",
       " 'disloyal': 710,\n",
       " 'forgiven': 711,\n",
       " 'horrible': 712,\n",
       " 'mistaken': 713,\n",
       " 'enemy': 714,\n",
       " 'pathetic': 715,\n",
       " 'picky': 716,\n",
       " 'sweet': 717,\n",
       " 'stalling': 718,\n",
       " 'talented': 719,\n",
       " 'acrobat': 720,\n",
       " 'distracted': 721,\n",
       " 'her': 722,\n",
       " 'pajamas': 723,\n",
       " 'kid': 724,\n",
       " 'brother': 725,\n",
       " 'never': 726,\n",
       " 'liked': 727,\n",
       " 'bartender': 728,\n",
       " 'cat': 729,\n",
       " 'lover': 730,\n",
       " 'gentleman': 731,\n",
       " 'grown': 732,\n",
       " 'historian': 733,\n",
       " 'nonsmoker': 734,\n",
       " 'sophomore': 735,\n",
       " 'side': 736,\n",
       " 'got': 737,\n",
       " 'flu': 738,\n",
       " 'for': 739,\n",
       " 'class': 740,\n",
       " 'intelligent': 741,\n",
       " 'struck': 742,\n",
       " 'like': 743,\n",
       " 'us': 744,\n",
       " 'minded': 745,\n",
       " 'unconscious': 746,\n",
       " 'father': 747,\n",
       " 'professor': 748,\n",
       " 'volunteer': 749,\n",
       " 'cooking': 750,\n",
       " 'dumbfounded': 751,\n",
       " 'russia': 752,\n",
       " 'frying': 753,\n",
       " 'fish': 754,\n",
       " 'time': 755,\n",
       " 'weekly': 756,\n",
       " 'years': 757,\n",
       " 'cousin': 758,\n",
       " 'bank': 759,\n",
       " 'clerk': 760,\n",
       " 'shutterbug': 761,\n",
       " 'swim': 762,\n",
       " 'already': 763,\n",
       " 'always': 764,\n",
       " 'ambidextrous': 765,\n",
       " 'beach': 766,\n",
       " 'between': 767,\n",
       " 'jobs': 768,\n",
       " 'by': 769,\n",
       " 'disappointed': 770,\n",
       " 'dissatisfied': 771,\n",
       " 'lunch': 772,\n",
       " 'fairly': 773,\n",
       " 'freaking': 774,\n",
       " 'america': 775,\n",
       " 'croatia': 776,\n",
       " 'england': 777,\n",
       " 'romania': 778,\n",
       " 'homeschooled': 779,\n",
       " 'housesitting': 780,\n",
       " 'attic': 781,\n",
       " 'house': 782,\n",
       " 'inviting': 783,\n",
       " 'looking': 784,\n",
       " 'killing': 785,\n",
       " 'beggar': 786,\n",
       " 'bluffing': 787,\n",
       " 'bragging': 788,\n",
       " 'counting': 789,\n",
       " 'dreaming': 790,\n",
       " 'paranoid': 791,\n",
       " 'why': 792,\n",
       " 'ideas': 793,\n",
       " 'shape': 794,\n",
       " 'overreacting': 795,\n",
       " 'proud': 796,\n",
       " 'this': 797,\n",
       " 'stronger': 798,\n",
       " 'super': 799,\n",
       " 'volunteering': 800,\n",
       " 'pianist': 801,\n",
       " 'obstinate': 802,\n",
       " 'wise': 803,\n",
       " 'russian': 804,\n",
       " 'artists': 805,\n",
       " 'singers': 806,\n",
       " 'fake': 807,\n",
       " 'traitors': 808,\n",
       " 'unique': 809,\n",
       " 'classmates': 810,\n",
       " 'downsizing': 811,\n",
       " 'down': 812,\n",
       " 'east': 813,\n",
       " 'west': 814,\n",
       " 'half': 815,\n",
       " 'college': 816,\n",
       " 'control': 817,\n",
       " 'lifeguards': 818,\n",
       " 'needed': 819,\n",
       " 'our': 820,\n",
       " 'own': 821,\n",
       " 'speechless': 822,\n",
       " 'surrounded': 823,\n",
       " 'taking': 824,\n",
       " 'owners': 825,\n",
       " 'children': 826,\n",
       " 'deranged': 827,\n",
       " 'fabulous': 828,\n",
       " 'gorgeous': 829,\n",
       " 'hopeless': 830,\n",
       " 'blame': 831,\n",
       " 'traitor': 832,\n",
       " 'conceited': 833,\n",
       " 'courteous': 834,\n",
       " 'fortunate': 835,\n",
       " 'obnoxious': 836,\n",
       " 'shivering': 837,\n",
       " 'talkative': 838,\n",
       " 'tense': 839,\n",
       " 'unethical': 840,\n",
       " 'wonderful': 841,\n",
       " 'eater': 842,\n",
       " 'biologist': 843,\n",
       " 'born': 844,\n",
       " 'daredevil': 845,\n",
       " 'detective': 846,\n",
       " 'dramatist': 847,\n",
       " 'physicist': 848,\n",
       " 'scientist': 849,\n",
       " 'forty': 850,\n",
       " 'desk': 851,\n",
       " 'beyond': 852,\n",
       " 'hope': 853,\n",
       " 'business': 854,\n",
       " 'incompetent': 855,\n",
       " 'influential': 856,\n",
       " 'teaching': 857,\n",
       " 'unrealistic': 858,\n",
       " 'walking': 859,\n",
       " 'journalist': 860,\n",
       " 'movie': 861,\n",
       " 'buff': 862,\n",
       " 'timer': 863,\n",
       " 'undergrad': 864,\n",
       " 'deep': 865,\n",
       " 'debt': 866,\n",
       " 'georgia': 867,\n",
       " 'water': 868,\n",
       " 'arrived': 869,\n",
       " 'and': 870,\n",
       " 'raking': 871,\n",
       " 'quick': 872,\n",
       " 'sound': 873,\n",
       " 'swimming': 874,\n",
       " 'tickled': 875,\n",
       " 'pink': 876,\n",
       " 'trusting': 877,\n",
       " 'person': 878,\n",
       " 'almost': 879,\n",
       " 'bread': 880,\n",
       " 'math': 881,\n",
       " 'die': 882,\n",
       " 'pleased': 883,\n",
       " 'little': 884,\n",
       " 'girl': 885,\n",
       " 'salesperson': 886,\n",
       " 'total': 887,\n",
       " 'wreck': 888,\n",
       " 'myself': 889,\n",
       " 'as': 890,\n",
       " 'school': 891,\n",
       " 'mercy': 892,\n",
       " 'aware': 893,\n",
       " 'awfully': 894,\n",
       " 'watched': 895,\n",
       " 'concentrating': 896,\n",
       " 'extremely': 897,\n",
       " 'dizzy': 898,\n",
       " 'flabbergasted': 899,\n",
       " 'bulgaria': 900,\n",
       " 'colombia': 901,\n",
       " 'city': 902,\n",
       " 'did': 903,\n",
       " 'jump': 904,\n",
       " 'irreplaceable': 905,\n",
       " 'guessing': 906,\n",
       " 'weight': 907,\n",
       " 'monster': 908,\n",
       " 'soldier': 909,\n",
       " 'dangerous': 910,\n",
       " 'rush': 911,\n",
       " 'miserable': 912,\n",
       " 'panicking': 913,\n",
       " 'persuaded': 914,\n",
       " 'fast': 915,\n",
       " 'coach': 916,\n",
       " 'baby': 917,\n",
       " 'maid': 918,\n",
       " 'overworked': 919,\n",
       " 'sore': 920,\n",
       " 'sort': 921,\n",
       " 'dubious': 922,\n",
       " 'bath': 923,\n",
       " 'totally': 924,\n",
       " 'uncomfortable': 925,\n",
       " 'neighbor': 926,\n",
       " 'beginner': 927,\n",
       " 'aggressive': 928,\n",
       " 'attractive': 929,\n",
       " 'unsociable': 930,\n",
       " 'fashionable': 931,\n",
       " 'point': 932,\n",
       " 'hyperactive': 933,\n",
       " 'daughter': 934,\n",
       " 'alike': 935,\n",
       " 'liars': 936,\n",
       " 'cannibals': 937,\n",
       " 'expensive': 938,\n",
       " 'guys': 939,\n",
       " 'undamaged': 940,\n",
       " 'australian': 941,\n",
       " 'related': 942,\n",
       " 'risk': 943,\n",
       " 'cowards': 944,\n",
       " 'changing': 945,\n",
       " 'defenseless': 946,\n",
       " 'great': 947,\n",
       " 'experienced': 948,\n",
       " 'north': 949,\n",
       " 'south': 950,\n",
       " 'handling': 951,\n",
       " 'journalists': 952,\n",
       " 'dressed': 953,\n",
       " 'killers': 954,\n",
       " 'schedule': 955,\n",
       " 'beer': 956,\n",
       " 'milk': 957,\n",
       " 'wine': 958,\n",
       " 'pulling': 959,\n",
       " 'problem': 960,\n",
       " 'actresses': 961,\n",
       " 'hilarious': 962,\n",
       " 'prisoner': 963,\n",
       " 'articulate': 964,\n",
       " 'again': 965,\n",
       " 'courageous': 966,\n",
       " 'disgusting': 967,\n",
       " 'hurting': 968,\n",
       " 'incredible': 969,\n",
       " 'productive': 970,\n",
       " 'remarkable': 971,\n",
       " 'scaring': 972,\n",
       " 'telling': 973,\n",
       " 'leader': 974,\n",
       " 'master': 975,\n",
       " 'polite': 976,\n",
       " 'driver': 977,\n",
       " 'fishmonger': 978,\n",
       " 'loser': 979,\n",
       " 'slim': 980,\n",
       " 'but': 981,\n",
       " 'drinking': 982,\n",
       " 'classmate': 983,\n",
       " 'colleague': 984,\n",
       " 'radio': 985,\n",
       " 'playing': 986,\n",
       " 'golf': 987,\n",
       " 'witted': 988,\n",
       " 'heartless': 989,\n",
       " 'come': 990,\n",
       " 'thick': 991,\n",
       " 'headed': 992,\n",
       " 'learned': 993,\n",
       " 'creationist': 994,\n",
       " 'walker': 995,\n",
       " 'filthy': 996,\n",
       " 'food': 997,\n",
       " 'critic': 998,\n",
       " 'ghostwriter': 999,\n",
       " 'goal': 1000,\n",
       " 'keeper': 1001,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同单词出现的次数\n",
    "output_lang.word2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Training Data\n",
    "\n",
    "To train, for each pair we will need an input tensor (indexes of the words in the input sentence) and target tensor (indexes of the words in the target sentence). While creating these vectors we will append the EOS token to both sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2],\n",
       "        [ 16],\n",
       "        [ 42],\n",
       "        [472],\n",
       "        [  1]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将一句话中的每个字母转为Index, 并在结尾加上终止符\n",
    "tensorFromSentence(output_lang, 'i am a boy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Seq2Seq Model\n",
    "\n",
    "### Seq2Seq的好处\n",
    "\n",
    "对比传统的单层的RNN来说, 可以不需要输入和输出是相同的长度的. \n",
    "\n",
    "下面是完整的思想, 这里的原文还是很不错的.\n",
    "\n",
    "Unlike sequence prediction with a single RNN, where every input corresponds to an output, the seq2seq model frees us from sequence length and order, which makes it ideal for translation between two languages.\n",
    "\n",
    "Consider the sentence “Je ne suis pas le chat noir” → “I am not the black cat”. Most of the words in the input sentence have a direct translation in the output sentence, but are in slightly different orders, e.g. “chat noir” and “black cat”. Because of the “ne/pas” construction there is also one more word in the input sentence. It would be difficult to produce a correct translation directly from the sequence of input words.\n",
    "\n",
    "With a seq2seq model the encoder creates a single vector which, in the ideal case, encodes the “meaning” of the input sequence into a single vector — a single point in some N dimensional space of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Encoder\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size=1, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size # 输入的时候batch_size\n",
    "        self.n_layers = n_layers # RNN中的层数\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.sentence_length = x.size(0) # 获取一句话的长度\n",
    "        embedded = self.embedding(x).view(self.sentence_length, 1, -1) # seq_len * batch_size * word_size\n",
    "        output = embedded\n",
    "        self.hidden = self.initHidden()\n",
    "        output, hidden = self.gru(output, self.hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.n_layers, self.batch_size, self.hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2],\n",
       "        [1858],\n",
       "        [ 253],\n",
       "        [ 453],\n",
       "        [ 138],\n",
       "        [   5],\n",
       "        [   1]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = tensorsFromPair(random.choice(pairs))\n",
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder测试\n",
    "encoder1 = EncoderRNN(input_lang.n_words, 256).to(device)\n",
    "output, hidden = encoder1(test_data[0].unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 1, 256])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Decoder\n",
    "\n",
    "The decoder is another RNN that takes the encoder output vector(s) and outputs a sequence of words to create the translation.\n",
    "\n",
    "#### Simple Decoder\n",
    "\n",
    "In the simplest seq2seq decoder we use only last output of the encoder. This last output is sometimes called the context vector as it encodes context from the entire sequence. This context vector is used as the initial hidden state of the decoder.\n",
    "\n",
    "At every step of decoding, the decoder is given an input token and hidden state. The initial input token is the start-of-string <SOS> token, and the first hidden state is the context vector (the encoder’s last hidden state).\n",
    "    \n",
    "### 问题\n",
    "\n",
    "- decoder下面每次出入的x是什么=>上一次的output\n",
    "- 如何计算误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Attention Decoder\n",
    "\n",
    "If only the context vector is passed betweeen the encoder and decoder, that single vector carries the burden of encoding the entire sentence.(词向量会有整个句子的含义)\n",
    "\n",
    "Attention allows the decoder network to “focus” on a different part of the encoder’s outputs for every step of the decoder’s own outputs. First we calculate a set of attention weights. These will be multiplied by the encoder output vectors to create a weighted combination. The result (called attn_applied in the code) should contain information about that specific part of the input sequence, and thus help the decoder choose the right output words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./data/Snipaste_2019-06-12_19-21-43.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttenDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttenDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        # x是输入, 这里有两种类型\n",
    "        # hidden是上一层中隐藏层的内容\n",
    "        # encoder_outputs里面是encoder的RNN的每一步的输出(不是最后一个的输出)\n",
    "        \n",
    "        embedded = self.embedding(x).view(1,1,-1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        # print('embedded.shape',embedded.shape)\n",
    "        \n",
    "        # ----------------------------\n",
    "        # 下面的attention weight表示:\n",
    "        # 连接输入的词向量和上一步的hide state并建立bp训练，\n",
    "        # 他们决定了attention权重\n",
    "        # -----------------------------\n",
    "        attn_weights = torch.cat((embedded[0],hidden[0]),1)\n",
    "        # print('attn_weights1',attn_weights.shape)\n",
    "        attn_weights = self.attn(attn_weights)\n",
    "        attn_weights = F.softmax(attn_weights,dim=1)\n",
    "        # print('attn_weights2',attn_weights.shape)\n",
    "        \n",
    "        # 这是做矩阵乘法\n",
    "        # 施加权重到所有的语义向量上\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        # print('attn_applied',attn_applied.shape)\n",
    "        \n",
    "        # 加了attention的语义向量和输入的词向量共同作为输\n",
    "        # 此处对应解码方式三+attention\n",
    "        output = torch.cat((embedded[0],attn_applied[0]),1)\n",
    "        # print('output1',output.shape)\n",
    "        \n",
    "        # 进入RNN之前，先过了一个全连接层\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        # print('output2',output.shape)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # print('output3',output.shape)\n",
    "        \n",
    "        # 输出分类结果\n",
    "        output = F.log_softmax(self.out(output[0]),dim=1)\n",
    "        # print('output4',output.shape)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 1, 256]), torch.Size([1, 1, 256]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output是encoder的输出, hidden是encoder的最后的hidden state\n",
    "output.shape, hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这个是第一个输入, 代表起始符\n",
    "test_data = torch.tensor([[SOS_token]]).to(device)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_weights1 torch.Size([1, 512])\n",
      "attn_weights2 torch.Size([1, 7])\n",
      "attn_applied torch.Size([1, 1, 256])\n",
      "output1 torch.Size([1, 512])\n",
      "output2 torch.Size([1, 1, 256])\n",
      "output3 torch.Size([1, 1, 256])\n",
      "output4 torch.Size([1, 2803])\n"
     ]
    }
   ],
   "source": [
    "# decoder测试\n",
    "decoder1 = AttenDecoder(256, output_lang.n_words, max_length=output.size(0)).to(device)\n",
    "output, hidden, attn_weights = decoder1(test_data, hidden, output.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output = torch.tensor([[1,2,3],[4,5,6]]).float()\n",
    "test_outputs = torch.zeros((5,3))\n",
    "test_outputs[:test_output.size(0)]=test_output\n",
    "test_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "To train we run the input sentence through the encoder, and keep track of every output and the latest hidden state. Then the decoder is given the <SOS> token as its first input, and the last hidden state of the encoder as its first hidden state.(总体训练流程)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    \"\"\"将秒转换为分钟\n",
    "    \"\"\"\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    \"\"\"打印已经花费的时间和预计花费的时间\n",
    "       预计花费的时间, 用 完成百分比的时间/现在完成的百分比 来预测\n",
    "    \"\"\"\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5 # 50%的概率使用teacher_forcing的模式\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    # encoder_outputs = torch.zeros(max_length, encoder.hidden_size).to(device)\n",
    "    # Encoder\n",
    "    encoder_output, encoder_hidden = encoder1(input_tensor.unsqueeze(1))\n",
    "    # 因为一个Decoder的MAX_LENGTH是固定长度的, 所以我们需要将encoder_output变为一样长的\n",
    "    encoder_output = encoder_output.squeeze(1)\n",
    "    encoder_outputs = torch.zeros(max_length, encoder_output.size(1)).to(device)\n",
    "    encoder_outputs[:encoder_output.size(0)] = encoder_output\n",
    "    \n",
    "    # Decoder\n",
    "    loss = 0 \n",
    "    decoder_hidden = encoder_hidden # encoder最后的hidden作为decoder的hidden\n",
    "    decoder_input = torch.tensor([[SOS_token]]).to(device)\n",
    "    # 判断是使用哪一种模式\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss = loss + criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di] # Teacher Forcing\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach() # detach from history as input\n",
    "            loss = loss + criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "    # 反向传播, 进行优化\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole training process looks like this:\n",
    "\n",
    "- Start a timer\n",
    "- Initialize optimizers and criterion\n",
    "- Create set of training pairs\n",
    "- Start empty losses array for plotting\n",
    "\n",
    "Then we call train many times and occasionally print the progress (% of examples, time so far, estimated time) and average loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0 # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    \n",
    "    # 初始化优化器\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    # 初始化样本\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters+1):\n",
    "        training_pair = training_pairs[iter-1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total = print_loss_total + loss\n",
    "        plot_loss_total = plot_loss_total + loss\n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure(figsize=(14,7))\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 47s (- 158m 38s) (500 0%) 3.6054\n",
      "1m 12s (- 119m 27s) (1000 1%) 3.2510\n",
      "1m 37s (- 106m 31s) (1500 1%) 2.9936\n",
      "2m 3s (- 100m 28s) (2000 2%) 2.8509\n",
      "2m 29s (- 97m 11s) (2500 2%) 2.7908\n",
      "2m 55s (- 94m 27s) (3000 3%) 2.6773\n",
      "3m 21s (- 92m 44s) (3500 3%) 2.6372\n",
      "3m 48s (- 91m 15s) (4000 4%) 2.5842\n",
      "4m 14s (- 90m 11s) (4500 4%) 2.5697\n",
      "4m 41s (- 89m 3s) (5000 5%) 2.4861\n",
      "5m 7s (- 88m 5s) (5500 5%) 2.5631\n",
      "5m 34s (- 87m 14s) (6000 6%) 2.4557\n",
      "6m 1s (- 86m 34s) (6500 6%) 2.3604\n",
      "6m 27s (- 85m 43s) (7000 7%) 2.3599\n",
      "6m 53s (- 84m 56s) (7500 7%) 2.3061\n",
      "7m 19s (- 84m 13s) (8000 8%) 2.2213\n",
      "7m 45s (- 83m 34s) (8500 8%) 2.2661\n",
      "8m 11s (- 82m 54s) (9000 9%) 2.1390\n",
      "8m 37s (- 82m 11s) (9500 9%) 2.2514\n",
      "9m 5s (- 81m 47s) (10000 10%) 2.1486\n",
      "9m 32s (- 81m 20s) (10500 10%) 2.1033\n",
      "9m 59s (- 80m 47s) (11000 11%) 2.0725\n",
      "10m 25s (- 80m 10s) (11500 11%) 1.9941\n",
      "10m 51s (- 79m 38s) (12000 12%) 2.0466\n",
      "11m 17s (- 79m 4s) (12500 12%) 1.9715\n",
      "11m 44s (- 78m 37s) (13000 13%) 1.9464\n",
      "12m 11s (- 78m 6s) (13500 13%) 1.9076\n",
      "12m 37s (- 77m 35s) (14000 14%) 1.8438\n",
      "13m 4s (- 77m 6s) (14500 14%) 1.9230\n",
      "13m 31s (- 76m 35s) (15000 15%) 1.7866\n",
      "13m 57s (- 76m 6s) (15500 15%) 1.8212\n",
      "14m 24s (- 75m 37s) (16000 16%) 1.8385\n",
      "14m 50s (- 75m 4s) (16500 16%) 1.7707\n",
      "15m 16s (- 74m 33s) (17000 17%) 1.8549\n",
      "15m 42s (- 74m 4s) (17500 17%) 1.7221\n",
      "16m 9s (- 73m 34s) (18000 18%) 1.6703\n",
      "16m 35s (- 73m 7s) (18500 18%) 1.7063\n",
      "17m 2s (- 72m 38s) (19000 19%) 1.6355\n",
      "17m 28s (- 72m 9s) (19500 19%) 1.6829\n",
      "17m 55s (- 71m 42s) (20000 20%) 1.7553\n",
      "18m 21s (- 71m 11s) (20500 20%) 1.5834\n",
      "18m 48s (- 70m 44s) (21000 21%) 1.6956\n",
      "19m 14s (- 70m 14s) (21500 21%) 1.5488\n",
      "19m 41s (- 69m 48s) (22000 22%) 1.6104\n",
      "20m 7s (- 69m 20s) (22500 22%) 1.5849\n",
      "20m 34s (- 68m 52s) (23000 23%) 1.5203\n",
      "21m 1s (- 68m 26s) (23500 23%) 1.4879\n",
      "21m 28s (- 67m 59s) (24000 24%) 1.5117\n",
      "21m 54s (- 67m 30s) (24500 24%) 1.4980\n",
      "22m 21s (- 67m 3s) (25000 25%) 1.4553\n",
      "22m 47s (- 66m 36s) (25500 25%) 1.5664\n",
      "23m 13s (- 66m 7s) (26000 26%) 1.4715\n",
      "23m 40s (- 65m 40s) (26500 26%) 1.4824\n",
      "24m 7s (- 65m 12s) (27000 27%) 1.3940\n",
      "24m 33s (- 64m 45s) (27500 27%) 1.3669\n",
      "25m 0s (- 64m 18s) (28000 28%) 1.4068\n",
      "25m 29s (- 63m 57s) (28500 28%) 1.3587\n",
      "25m 57s (- 63m 33s) (29000 28%) 1.3278\n",
      "26m 24s (- 63m 7s) (29500 29%) 1.2895\n",
      "26m 50s (- 62m 38s) (30000 30%) 1.2803\n",
      "27m 17s (- 62m 10s) (30500 30%) 1.2953\n",
      "27m 43s (- 61m 41s) (31000 31%) 1.3539\n",
      "28m 9s (- 61m 13s) (31500 31%) 1.1853\n",
      "28m 35s (- 60m 45s) (32000 32%) 1.2504\n",
      "29m 2s (- 60m 18s) (32500 32%) 1.1967\n",
      "29m 28s (- 59m 50s) (33000 33%) 1.2162\n",
      "29m 55s (- 59m 23s) (33500 33%) 1.1349\n",
      "30m 21s (- 58m 56s) (34000 34%) 1.3058\n",
      "30m 48s (- 58m 29s) (34500 34%) 1.2266\n",
      "31m 14s (- 58m 0s) (35000 35%) 1.2795\n",
      "31m 40s (- 57m 33s) (35500 35%) 1.1727\n",
      "32m 7s (- 57m 5s) (36000 36%) 1.2520\n",
      "32m 33s (- 56m 39s) (36500 36%) 1.2045\n",
      "33m 0s (- 56m 12s) (37000 37%) 1.2001\n",
      "33m 26s (- 55m 44s) (37500 37%) 1.1644\n",
      "33m 53s (- 55m 17s) (38000 38%) 1.0936\n",
      "34m 19s (- 54m 50s) (38500 38%) 1.0935\n",
      "34m 46s (- 54m 22s) (39000 39%) 1.1274\n",
      "35m 12s (- 53m 55s) (39500 39%) 1.0829\n",
      "35m 39s (- 53m 28s) (40000 40%) 1.0652\n",
      "36m 5s (- 53m 1s) (40500 40%) 1.0576\n",
      "36m 32s (- 52m 35s) (41000 41%) 1.0497\n",
      "36m 58s (- 52m 7s) (41500 41%) 1.0729\n",
      "37m 25s (- 51m 40s) (42000 42%) 1.0579\n",
      "37m 52s (- 51m 14s) (42500 42%) 1.1397\n",
      "38m 18s (- 50m 47s) (43000 43%) 1.0395\n",
      "38m 45s (- 50m 19s) (43500 43%) 0.9922\n",
      "39m 11s (- 49m 52s) (44000 44%) 1.0096\n",
      "39m 38s (- 49m 26s) (44500 44%) 0.9736\n",
      "40m 4s (- 48m 59s) (45000 45%) 0.9718\n",
      "40m 31s (- 48m 32s) (45500 45%) 0.8947\n",
      "40m 58s (- 48m 5s) (46000 46%) 0.9138\n",
      "41m 24s (- 47m 38s) (46500 46%) 0.9302\n",
      "41m 51s (- 47m 12s) (47000 47%) 0.8652\n",
      "42m 18s (- 46m 45s) (47500 47%) 0.9090\n",
      "42m 45s (- 46m 19s) (48000 48%) 0.9478\n",
      "43m 12s (- 45m 53s) (48500 48%) 0.9157\n",
      "43m 38s (- 45m 25s) (49000 49%) 0.8517\n",
      "44m 5s (- 44m 58s) (49500 49%) 0.8683\n",
      "44m 31s (- 44m 31s) (50000 50%) 0.9749\n",
      "44m 58s (- 44m 4s) (50500 50%) 0.9147\n",
      "45m 24s (- 43m 37s) (51000 51%) 0.8217\n",
      "45m 51s (- 43m 11s) (51500 51%) 0.9697\n",
      "46m 18s (- 42m 44s) (52000 52%) 0.8711\n",
      "46m 44s (- 42m 17s) (52500 52%) 0.8078\n",
      "47m 11s (- 41m 50s) (53000 53%) 0.8632\n",
      "47m 37s (- 41m 24s) (53500 53%) 0.8896\n",
      "48m 4s (- 40m 57s) (54000 54%) 0.7512\n",
      "48m 31s (- 40m 30s) (54500 54%) 0.8333\n",
      "48m 58s (- 40m 4s) (55000 55%) 0.8303\n",
      "49m 25s (- 39m 37s) (55500 55%) 0.7942\n",
      "49m 52s (- 39m 11s) (56000 56%) 0.7817\n",
      "50m 19s (- 38m 44s) (56500 56%) 0.7935\n",
      "50m 46s (- 38m 18s) (57000 56%) 0.8454\n",
      "51m 12s (- 37m 51s) (57500 57%) 0.7482\n",
      "51m 39s (- 37m 24s) (58000 57%) 0.8122\n",
      "52m 6s (- 36m 58s) (58500 58%) 0.7849\n",
      "52m 33s (- 36m 31s) (59000 59%) 0.7789\n",
      "52m 59s (- 36m 4s) (59500 59%) 0.7484\n",
      "53m 26s (- 35m 37s) (60000 60%) 0.7296\n",
      "53m 52s (- 35m 10s) (60500 60%) 0.7496\n",
      "54m 20s (- 34m 44s) (61000 61%) 0.7323\n",
      "54m 46s (- 34m 17s) (61500 61%) 0.7775\n",
      "55m 13s (- 33m 50s) (62000 62%) 0.8082\n",
      "55m 40s (- 33m 24s) (62500 62%) 0.7497\n",
      "56m 6s (- 32m 57s) (63000 63%) 0.6935\n",
      "56m 33s (- 32m 30s) (63500 63%) 0.7287\n",
      "56m 59s (- 32m 3s) (64000 64%) 0.7438\n",
      "57m 26s (- 31m 36s) (64500 64%) 0.6994\n",
      "57m 52s (- 31m 10s) (65000 65%) 0.7005\n",
      "58m 19s (- 30m 43s) (65500 65%) 0.6712\n",
      "58m 46s (- 30m 16s) (66000 66%) 0.6728\n",
      "59m 13s (- 29m 50s) (66500 66%) 0.7063\n",
      "59m 40s (- 29m 23s) (67000 67%) 0.6627\n",
      "60m 7s (- 28m 56s) (67500 67%) 0.6275\n",
      "60m 33s (- 28m 30s) (68000 68%) 0.5899\n",
      "61m 0s (- 28m 3s) (68500 68%) 0.6376\n",
      "61m 27s (- 27m 36s) (69000 69%) 0.6509\n",
      "61m 54s (- 27m 9s) (69500 69%) 0.6442\n",
      "62m 21s (- 26m 43s) (70000 70%) 0.5847\n",
      "62m 48s (- 26m 16s) (70500 70%) 0.5790\n",
      "63m 14s (- 25m 49s) (71000 71%) 0.6407\n",
      "63m 40s (- 25m 22s) (71500 71%) 0.6293\n",
      "64m 7s (- 24m 56s) (72000 72%) 0.6025\n",
      "64m 34s (- 24m 29s) (72500 72%) 0.6072\n",
      "65m 1s (- 24m 2s) (73000 73%) 0.6622\n",
      "65m 28s (- 23m 36s) (73500 73%) 0.6321\n",
      "65m 54s (- 23m 9s) (74000 74%) 0.5994\n",
      "66m 21s (- 22m 42s) (74500 74%) 0.6453\n",
      "66m 49s (- 22m 16s) (75000 75%) 0.6419\n",
      "67m 16s (- 21m 49s) (75500 75%) 0.6060\n",
      "67m 43s (- 21m 23s) (76000 76%) 0.5427\n",
      "68m 10s (- 20m 56s) (76500 76%) 0.5305\n",
      "68m 37s (- 20m 29s) (77000 77%) 0.5529\n",
      "69m 4s (- 20m 3s) (77500 77%) 0.5740\n",
      "69m 30s (- 19m 36s) (78000 78%) 0.5708\n",
      "69m 57s (- 19m 9s) (78500 78%) 0.6102\n",
      "70m 24s (- 18m 43s) (79000 79%) 0.5983\n",
      "70m 51s (- 18m 16s) (79500 79%) 0.5537\n",
      "71m 17s (- 17m 49s) (80000 80%) 0.5543\n",
      "71m 45s (- 17m 22s) (80500 80%) 0.5720\n",
      "72m 12s (- 16m 56s) (81000 81%) 0.5088\n",
      "72m 38s (- 16m 29s) (81500 81%) 0.4620\n",
      "73m 5s (- 16m 2s) (82000 82%) 0.5441\n",
      "73m 32s (- 15m 36s) (82500 82%) 0.5021\n",
      "73m 59s (- 15m 9s) (83000 83%) 0.5288\n",
      "74m 26s (- 14m 42s) (83500 83%) 0.5472\n",
      "74m 54s (- 14m 16s) (84000 84%) 0.5054\n",
      "75m 21s (- 13m 49s) (84500 84%) 0.5879\n",
      "75m 48s (- 13m 22s) (85000 85%) 0.4440\n",
      "76m 15s (- 12m 56s) (85500 85%) 0.4852\n",
      "76m 42s (- 12m 29s) (86000 86%) 0.4460\n",
      "77m 8s (- 12m 2s) (86500 86%) 0.5177\n",
      "77m 35s (- 11m 35s) (87000 87%) 0.4314\n",
      "78m 2s (- 11m 8s) (87500 87%) 0.4672\n",
      "78m 29s (- 10m 42s) (88000 88%) 0.4719\n",
      "78m 56s (- 10m 15s) (88500 88%) 0.4537\n",
      "79m 23s (- 9m 48s) (89000 89%) 0.4931\n",
      "79m 49s (- 9m 21s) (89500 89%) 0.4683\n",
      "80m 16s (- 8m 55s) (90000 90%) 0.4768\n",
      "80m 42s (- 8m 28s) (90500 90%) 0.5349\n",
      "81m 9s (- 8m 1s) (91000 91%) 0.5130\n",
      "81m 36s (- 7m 34s) (91500 91%) 0.4231\n",
      "82m 3s (- 7m 8s) (92000 92%) 0.4685\n",
      "82m 30s (- 6m 41s) (92500 92%) 0.4131\n",
      "82m 57s (- 6m 14s) (93000 93%) 0.4845\n",
      "83m 24s (- 5m 47s) (93500 93%) 0.4826\n",
      "83m 51s (- 5m 21s) (94000 94%) 0.4293\n",
      "84m 17s (- 4m 54s) (94500 94%) 0.4300\n",
      "84m 44s (- 4m 27s) (95000 95%) 0.4438\n",
      "85m 11s (- 4m 0s) (95500 95%) 0.4020\n",
      "85m 38s (- 3m 34s) (96000 96%) 0.4849\n",
      "86m 4s (- 3m 7s) (96500 96%) 0.4203\n",
      "86m 31s (- 2m 40s) (97000 97%) 0.3874\n",
      "86m 57s (- 2m 13s) (97500 97%) 0.4215\n",
      "87m 24s (- 1m 47s) (98000 98%) 0.3926\n",
      "87m 51s (- 1m 20s) (98500 98%) 0.4236\n",
      "88m 17s (- 0m 53s) (99000 99%) 0.3752\n",
      "88m 43s (- 0m 26s) (99500 99%) 0.4225\n",
      "89m 10s (- 0m 0s) (100000 100%) 0.4856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = AttenDecoder(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, n_iters=100000, print_every=500, plot_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluation is mostly the same as training, but there are no targets so we simply feed the decoder’s predictions back to itself for each step. Every time it predicts a word we add it to the output string, and if it predicts the EOS token we stop there. We also store the decoder’s attention outputs for display later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        \n",
    "        # Encoder\n",
    "        encoder_output, encoder_hidden = encoder1(input_tensor.unsqueeze(1))\n",
    "        encoder_output = encoder_output.squeeze(1)\n",
    "        encoder_outputs = torch.zeros(max_length, encoder_output.size(1)).to(device)\n",
    "        encoder_outputs[:encoder_output.size(0)] = encoder_output\n",
    "        \n",
    "        \n",
    "        # Decoder\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length) # 记录输入每个词时的attention weight\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = attn_weights.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                \"\"\"遇到终止符就停止\n",
    "                \"\"\"\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                \"\"\"把decode的word加入数组中\n",
    "                \"\"\"\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "                \n",
    "            # 下一个的输入是上一个的输出\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words,decoder_attentions[:di+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words,_ = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> je suis membre de ce club de tennis .\n",
      "= i m in the tennis club .\n",
      "< i m good tennis in the club . <EOS>\n",
      "\n",
      "> vous n etes jamais chez vous .\n",
      "= you re never at home .\n",
      "< you re never at home . <EOS>\n",
      "\n",
      "> elle est debutante .\n",
      "= she is a beginner .\n",
      "< she is a beginner . <EOS>\n",
      "\n",
      "> je suis tres heureux de vous rencontrer .\n",
      "= i m very glad to meet you .\n",
      "< i m very glad to meet you . <EOS>\n",
      "\n",
      "> je suis heureux que vous l ayez aime .\n",
      "= i m happy you liked it .\n",
      "< i m happy you liked it . <EOS>\n",
      "\n",
      "> tu ne saignes pas .\n",
      "= you re not bleeding .\n",
      "< you re not bleeding . <EOS>\n",
      "\n",
      "> elle est aimee de ses amies .\n",
      "= she s loved by her friends .\n",
      "< she s loved by her friends . <EOS>\n",
      "\n",
      "> vous faites erreur a ce propos .\n",
      "= you are mistaken about that .\n",
      "< you are mistaken about that . <EOS>\n",
      "\n",
      "> vous vous etes trompe d avion .\n",
      "= you are on the wrong plane .\n",
      "< you re on the wrong plane . <EOS>\n",
      "\n",
      "> nous en avons fini .\n",
      "= we re finished .\n",
      "< we re through . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27717aa7ef0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, attentions = evaluate(encoder1, decoder1, \"je suis trop froid .\")\n",
    "plt.matshow(attentions.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better viewing experience we will do the extra work of adding axes and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更好的可视化\n",
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder1, decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = c est un jeune directeur plein de talent .\n",
      "output = he s a talented critic here . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "19098450bf15c53d098daaa826d9da088c802e1c794f68cf2c07b6612df9a31b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
